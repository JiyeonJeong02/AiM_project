import requests
import zipfile
import os
from io import BytesIO
from bs4 import BeautifulSoup
from dotenv import load_dotenv
import re  # ì •ê·œ í‘œí˜„ì‹ ì‚¬ìš©
"""
# Trouble-Shooting

ê¸°ì¡´ì—ëŠ” TITLE íƒœê·¸ë¥¼ í†µí•´ì„œ, ê´€ë ¨ ë‚´ìš©ì„ ì¡°íšŒí•˜ë ¤ê³  í•¨. êµ¬ì¡°ë¥¼ ì´ìš©í•œ ì½”ë”©ì„ ì‹œë„
-> TITLEì´ ì œëŒ€ë¡œ ì°¾ì•„ì§€ì§€ ì•ŠìŒ.
=> extract_section("íšŒì‚¬ì˜ ê°œìš”"), extract_section("ì‚¬ì—…ì˜ ê°œìš”")ë¡œ ë³€ê²½í•˜ì—¬ ì •í™•í•œ TITLEì„ ì°¾ë„ë¡ ìˆ˜ì •
=> XML ë‚´ì—ì„œ ì •í™•í•œ ì„¹ì…˜ëª…ì„ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ â†’ ì •í™•í•œ ìœ„ì¹˜ì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ìˆì—ˆìŒ
=> **ì„¹ì…˜ëª…ì´ ë‹¤ë¥¼ ì‹œ ì—ëŸ¬ê°€ ë‚  ê°€ëŠ¥ì„±ì´ ìˆìŒ. ì•ìœ¼ë¡œ ìœ ì˜í•  ê²ƒ**
/
ë³¸ë¬¸ë˜í•œ, ê¸°ì¡´ì—ëŠ” TITLE íƒœê·¸ë¥¼ ì°¾ê³ , P íƒœê·¸ë§Œ ê²€ìƒ‰í–ˆìŒ. ì´ ê²½ìš° ë³¸ë¬¸ ë‚´ìš©ì´ TABLE, SPAN íƒœê·¸ì— í¬í•¨ëœ ê²½ìš° ì°¾ì§€ ëª»í•¨
=> find_all_next()ë¥¼ ì‚¬ìš©í•˜ì—¬ TITLE íƒœê·¸ ì´í›„ì˜ ëª¨ë“  P, TABLE, SPAN íƒœê·¸ì˜ ë‚´ìš©ì„ ê²€ìƒ‰
=> ì¦‰, ë³¸ë¬¸ ë‚´ìš©ì´ ë‹¤ì–‘í•œ íƒœê·¸ì— í¬í•¨ë˜ì–´ ìˆì–´ë„ ë¹ ì§ì—†ì´ ê°€ì ¸ì˜¬ ìˆ˜ ìˆê²Œ ìˆ˜ì •ë¨
"""

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# Open DART API í‚¤ ê°€ì ¸ì˜¤ê¸°
API_KEY = os.getenv('DART_API_KEY')

# ë‹¤ìš´ë¡œë“œí•  ê³µì‹œì˜ ì ‘ìˆ˜ë²ˆí˜¸
rcept_no = '20240814003284'  # ì‚¼ì„±ì „ì ë°˜ê¸°ë³´ê³ ì„œ ì˜ˆì œ

# API ìš”ì²­ URL
url = "https://opendart.fss.or.kr/api/document.xml"

# ìš”ì²­ íŒŒë¼ë¯¸í„°
params = {
    'crtfc_key': API_KEY,
    'rcept_no': rcept_no
}

# ì €ì¥í•  í´ë” ìƒì„±
save_dir = "downloads"
os.makedirs(save_dir, exist_ok=True)

# API ìš”ì²­ ë° íŒŒì¼ ë‹¤ìš´ë¡œë“œ
response = requests.get(url, params=params)
if response.status_code == 200:
    with zipfile.ZipFile(BytesIO(response.content)) as z:
        file_list = z.namelist()
        print(f"ğŸ“Œ ZIP ë‚´ë¶€ íŒŒì¼ ëª©ë¡: {file_list}")

        # ì²« ë²ˆì§¸ íŒŒì¼ ìë™ ì„ íƒ
        extracted_file = file_list[0]
        xml_path = os.path.join(save_dir, extracted_file)

        # íŒŒì¼ ì €ì¥
        with open(xml_path, "wb") as f:
            f.write(z.read(extracted_file))

        print(f"âœ… ì €ì¥ ì™„ë£Œ: {xml_path}")

else:
    raise Exception(f"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: ìƒíƒœ ì½”ë“œ {response.status_code}")

# XML íŒŒì¼ ë¡œë“œ (UTF-8ë¡œ ê°•ì œ ë³€í™˜)
with open(xml_path, "r", encoding="utf-8", errors="ignore") as f:
    xml_content = f.read()

# ğŸ”¹ BeautifulSoupì„ ì‚¬ìš©í•œ XML íŒŒì‹± (XML íŒŒì„œ ì ìš©)
soup = BeautifulSoup(xml_content, features="xml")

# ğŸ”¹ "íšŒì‚¬ ê°œìš”" ë° "ì‚¬ì—… ê°œìš”" ì°¾ê¸°
def extract_section(section_title):
    """
    íŠ¹ì • ì„¹ì…˜ ì œëª©ì„ ì°¾ì•„ì„œ ë‹¤ìŒì— ë‚˜ì˜¤ëŠ” ë³¸ë¬¸ ë‚´ìš©ì„ ì¶”ì¶œ
    """
    # ì •ê·œ í‘œí˜„ì‹ì„ ì‚¬ìš©í•˜ì—¬ "ì‚¬ì—…ì˜ ê°œìš”"ì™€ ê´€ë ¨ëœ ëª¨ë“  TITLEì„ ì°¾ìŒ
    section = soup.find("TITLE", string=lambda text: text and re.search(rf"\d*\.*\s*{section_title}", text))
    if section:
        content = []
        for sibling in section.find_all_next():
            if sibling.name == "TITLE":  # ë‹¤ìŒ ì„¹ì…˜ì´ ë‚˜ì˜¤ë©´ ì¤‘ë‹¨
                break
            if sibling.name in ["P", "TABLE", "SPAN"]:  # ë³¸ë¬¸ ë‚´ìš©ì´ í¬í•¨ëœ íƒœê·¸
                text = sibling.get_text(strip=True)  # ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
                if text and text not in content:  # ì¤‘ë³µ ë°ì´í„° ì…ë ¥ ë°©ì§€
                    content.append(text)

        return "\n".join(content) if content else "í•´ë‹¹ ì„¹ì…˜ì˜ ë³¸ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    return "í•´ë‹¹ ì„¹ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

company_overview = extract_section("íšŒì‚¬ì˜ ê°œìš”")  # ìˆ«ì í¬í•¨ ì—¬ë¶€ ê´€ê³„ì—†ì´ ê²€ìƒ‰
business_overview = extract_section("ì‚¬ì—…ì˜ ê°œìš”")  # ìˆ«ì í¬í•¨ ì—¬ë¶€ ê´€ê³„ì—†ì´ ê²€ìƒ‰

# ê²°ê³¼ ì¶œë ¥
print("\nğŸ“Œ [íšŒì‚¬ ê°œìš”]")
print(company_overview)

print("\nğŸ“Œ [ì‚¬ì—… ê°œìš”]")
print(business_overview)
