import requests
import zipfile
import os
import xml.etree.ElementTree as ET
from io import BytesIO
from bs4 import BeautifulSoup
import json
import time
import csv
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# Open DART API í‚¤ ê°€ì ¸ì˜¤ê¸°
API_KEY = os.getenv("DART_API_KEY")

# ì €ì¥í•  í´ë” ìƒì„±
save_dir = "downloads"
os.makedirs(save_dir, exist_ok=True)

# ğŸ”¹ ëŒ€ê¸°ì—… 5ê°œ ì„ ì • (KOSPI ëŒ€í˜•ì£¼) (ì´ë¦„ ê¸°ì¤€ìœ¼ë¡œ ê²€ìƒ‰)
target_companies = ["ì‚¼ì„±ì „ì", "SKí•˜ì´ë‹‰ìŠ¤", "í˜„ëŒ€ìë™ì°¨", "NAVER", "ì¹´ì¹´ì˜¤"]

# ğŸ”¹ ëª¨ë“  ê¸°ì—…ì˜ `corp_code` ê°€ì ¸ì˜¤ê¸°
def get_all_corp_codes():
    url = f"https://opendart.fss.or.kr/api/corpCode.xml?crtfc_key={API_KEY}"
    response = requests.get(url)

    if response.status_code == 200:
        with zipfile.ZipFile(BytesIO(response.content)) as zfile:
            zfile.extractall(save_dir)

        xml_path = os.path.join(save_dir, "corpCode.xml")
        tree = ET.parse(xml_path)
        root = tree.getroot()

        corp_codes = {}
        for corp in root.findall("list"):
            corp_name = corp.find("corp_name").text.strip()
            corp_code = corp.find("corp_code").text.strip()
            corp_codes[corp_name] = corp_code

        return corp_codes
    else:
        print("âŒ ê¸°ì—… ì½”ë“œ XML ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
        return {}

# ğŸ”¹ ìµœì‹  ë³´ê³ ì„œ ì ‘ìˆ˜ë²ˆí˜¸ (rcept_no) ê°€ì ¸ì˜¤ê¸° (í•œ ë²ˆì˜ API í˜¸ì¶œ)
def get_latest_rcept_no(corp_codes):
    url = "https://opendart.fss.or.kr/api/list.json"
    params = {
        "crtfc_key": API_KEY,
        "bgn_de": "20230101",  # 1ë…„ ë™ì•ˆì˜ ìµœì‹  ë³´ê³ ì„œ ê²€ìƒ‰
        "end_de": "20241231",
        "page_no": 1,
        "page_count": 50
    }

    response = requests.get(url, params=params)
    if response.status_code == 200:
        data = response.json()
        report_mapping = {}

        if "list" in data:
            for report in data["list"]:
                corp_code = report["corp_code"]
                report_name = report["report_nm"]
                rcept_no = report["rcept_no"]

                if corp_code in corp_codes.values() and "ê°ì‚¬ë³´ê³ ì„œ" not in report_name:
                    report_mapping[corp_code] = rcept_no

        return report_mapping
    return {}

# ğŸ”¹ ì‚¬ì—… ê°œìš” ì¶”ì¶œ (í•œ ë²ˆì˜ API í˜¸ì¶œ)
def extract_business_overview(rcept_no):
    url = "https://opendart.fss.or.kr/api/document.xml"
    params = {"crtfc_key": API_KEY, "rcept_no": rcept_no}

    response = requests.get(url)
    if response.status_code == 200:
        with zipfile.ZipFile(BytesIO(response.content)) as z:
            file_list = z.namelist()
            extracted_file = file_list[0]
            xml_path = os.path.join(save_dir, extracted_file)

            with open(xml_path, "wb") as f:
                f.write(z.read(extracted_file))

    else:
        return None

    # XML íŒŒì¼ ë¡œë“œ ë° BeautifulSoupìœ¼ë¡œ íŒŒì‹±
    with open(xml_path, "r", encoding="utf-8", errors="ignore") as f:
        xml_content = f.read()

    soup = BeautifulSoup(xml_content, features="xml")

    def extract_section(section_title):
        section = soup.find("TITLE", string=lambda text: text and section_title in text)
        if not section:
            return None

        content = []
        for sibling in section.find_all_next():
            if sibling.name == "TITLE":
                break
            if sibling.name in ["P", "TABLE", "SPAN", "DIV"]:
                text = sibling.get_text(strip=True)
                if text and text not in content:
                    content.append(text)

        return "\n".join(content) if content else None

    return extract_section("ì‚¬ì—…ì˜ ê°œìš”") or extract_section("ì‚¬ì—… ë‚´ìš©")

# ğŸ”¹ ì‹¤í–‰ ê³¼ì •
corp_codes = get_all_corp_codes()

# âœ… ë„¤ì´ë²„, ì¹´ì¹´ì˜¤ ë“± 5ê°œ ê¸°ì—…ì˜ ì‹¤ì œ `corp_code` í™•ì¸
selected_corp_codes = {name: corp_codes[name] for name in target_companies if name in corp_codes}

# âœ… 5ê°œ ê¸°ì—…ì˜ ìµœì‹  ë³´ê³ ì„œ ì ‘ìˆ˜ë²ˆí˜¸ ê°€ì ¸ì˜¤ê¸° (API 1íšŒ í˜¸ì¶œ)
latest_reports = get_latest_rcept_no(selected_corp_codes)

# âœ… 5ê°œ ê¸°ì—…ì˜ ê¸°ì—… ê°œìš” ë° ì‚¬ì—… ê°œìš” ê°€ì ¸ì˜¤ê¸° (API 1íšŒ í˜¸ì¶œ)
all_data = []

for corp_name, corp_code in selected_corp_codes.items():
    rcept_no = latest_reports.get(corp_code)
    business_overview = extract_business_overview(rcept_no) if rcept_no else "ì‚¬ì—… ê°œìš” ì—†ìŒ"

    # ê¸°ì—… ê°œìš” ì •ë³´ ê°€ì ¸ì˜¤ê¸° (API 1íšŒ í˜¸ì¶œ)
    url = "https://opendart.fss.or.kr/api/company.json"
    params = {"crtfc_key": API_KEY, "corp_code": corp_code}

    response = requests.get(url, params=params)
    if response.status_code == 200:
        data = response.json()
        if data["status"] == "000":
            company_info = {
                "ê¸°ì—…ëª…": data.get("corp_name", "ì •ë³´ ì—†ìŒ"),
                "ì˜ë¬¸ëª…": data.get("corp_name_eng", "ì •ë³´ ì—†ìŒ"),
                "ì„¤ë¦½ì¼": data.get("est_dt", "ì •ë³´ ì—†ìŒ"),
                "ëŒ€í‘œìëª…": data.get("ceo_nm", "ì •ë³´ ì—†ìŒ"),
                "ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸": data.get("bizr_no", "ì •ë³´ ì—†ìŒ"),
                "ë²•ì¸ë“±ë¡ë²ˆí˜¸": data.get("jurir_no", "ì •ë³´ ì—†ìŒ"),
                "ì—…ì¢…": data.get("induty_code", "ì •ë³´ ì—†ìŒ"),
                "ì£¼ê¶Œìƒì¥ ì—¬ë¶€": data.get("stock_name", "ì •ë³´ ì—†ìŒ"),
                "ìƒì¥ì¼": data.get("list_dt", "ì •ë³´ ì—†ìŒ"),
                "í™ˆí˜ì´ì§€": data.get("hm_url", "ì •ë³´ ì—†ìŒ"),
                "ì‚¬ì—… ê°œìš”": business_overview
            }
            all_data.append(company_info)

    time.sleep(1)  # API ìš”ì²­ ì œí•œ ë°©ì§€ë¥¼ ìœ„í•´ 1ì´ˆ ëŒ€ê¸°

# ğŸ”¹ CSV íŒŒì¼ë¡œ ì €ì¥
csv_filename = "ëŒ€ê¸°ì—…_ê¸°ì—…ê°œìš”.csv"
with open(csv_filename, mode="w", encoding="utf-8-sig", newline="") as file:
    writer = csv.DictWriter(file, fieldnames=all_data[0].keys())
    writer.writeheader()
    writer.writerows(all_data)

print(f"ğŸ“„ CSV íŒŒì¼ ì €ì¥ ì™„ë£Œ: {csv_filename}")
