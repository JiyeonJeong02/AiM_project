import os
import sys  # âœ… ëª…ë ¹ì¤„ ì¸ì ì²˜ë¦¬ ì¶”ê°€
import json
import requests
import logging
import zipfile
from io import BytesIO
from typing import List, Dict
from datetime import datetime
import time
from dotenv import load_dotenv
from transformers import pipeline, AutoTokenizer
import xml.etree.ElementTree as ET
import os


# ë³´ê³ ì„œ í™•ì¸ ìš©
OUTPUT_DIR = "output"
os.makedirs(OUTPUT_DIR, exist_ok=True)
# ë””ë²„ê¹… ìš©
DEBUG_DIR = "debug"
os.makedirs(DEBUG_DIR, exist_ok=True)


# ë¡œê·¸ ì„¤ì •
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

class DartETLPipeline:
    def __init__(self, batch_size=10, daily_api_limit=1000):
        """DART ETL íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”"""
        load_dotenv()
        self.api_key = os.getenv("DART_API_KEY")
        self.es_url = os.getenv("ELASTICSEARCH_URL")
        self.index_name = os.getenv("INDEX_NAME", "business_overview")

        if not self.api_key:
            raise ValueError("DART_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        if not self.es_url:
            raise ValueError("ELASTICSEARCH_URL í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        self.base_url = "https://opendart.fss.or.kr/api"
        self.batch_size = batch_size
        self.daily_api_limit = daily_api_limit
        self.api_call_count = 0

        # í†µê³„ ë³€ìˆ˜
        self.total_companies = 0
        self.skipped_companies = 0
        self.successful_uploads = 0
        self.failed_uploads = 0

        # KoBART ëª¨ë¸ ë¡œë“œ
        logger.info("KoBART ìš”ì•½ ëª¨ë¸ ë¡œë“œ ì¤‘...")
        self.model_name = "digit82/kobart-summarization"
        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
        self.summarizer = pipeline("summarization", model=self.model_name, tokenizer=self.tokenizer)
        logger.info("KoBART ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")

    def test_elasticsearch_connection(self) -> bool:
        """Elasticsearch ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            response = requests.get(self.es_url, timeout=10)
            logger.info(f"Elasticsearch ì—°ê²° ìƒíƒœ ì½”ë“œ: {response.status_code}")
            return response.status_code == 200
        except Exception as e:
            logger.error(f"Elasticsearch ì—°ê²° ì‹¤íŒ¨: {e}")
            return False

    def get_corp_list(self, start_idx: int, end_idx: int) -> List[Dict]:
        """DART APIì—ì„œ ìƒì¥ì‚¬ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (corpCode.xmlì„ output í´ë”ì— ì €ì¥)"""
        url = f"{self.base_url}/corpCode.xml"
        params = {'crtfc_key': self.api_key}

        try:
            response = requests.get(url, params=params)
            if response.status_code != 200:
                return []

            file_path = os.path.join(OUTPUT_DIR, "corpCode.xml")  # âœ… output í´ë”ì— ì €ì¥
            with open(file_path, "wb") as f:
                f.write(response.content)
            logger.info(f"ğŸ“‚ ê¸°ì—… ì½”ë“œ XML ë°ì´í„° ì €ì¥ ì™„ë£Œ: {file_path}")

            with zipfile.ZipFile(BytesIO(response.content)) as z:
                xml_data = z.read(z.namelist()[0])

            root = ET.fromstring(xml_data)
            all_corp_list = [
                {
                    'corp_code': corp.findtext('corp_code'),
                    'corp_name': corp.findtext('corp_name'),
                    'stock_code': corp.findtext('stock_code', '').strip()
                }
                for corp in root.findall('.//list')
                if corp.findtext('stock_code')
            ]

            logger.info(f"ğŸ“Š ì „ì²´ ê¸°ì—… ê°œìˆ˜: {len(all_corp_list)}ê°œ")
            end_idx = min(end_idx, len(all_corp_list))  # ë²”ìœ„ë¥¼ ì´ˆê³¼í•˜ì§€ ì•Šë„ë¡ ì¡°ì •
            selected_corps = all_corp_list[start_idx:end_idx]

            logger.info(f"ğŸ”¢ ì„ íƒëœ ê¸°ì—… ê°œìˆ˜: {len(selected_corps)} (ë²”ìœ„: {start_idx}~{end_idx})")
            return selected_corps

        except Exception as e:
            logger.error(f"ê¸°ì—… ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
            
    def get_business_report(self, corp_code: str) -> str:
        """ì‚¬ì—… ë³´ê³ ì„œ, ë°˜ê¸° ë³´ê³ ì„œ, ë¶„ê¸° ë³´ê³ ì„œ ì¤‘ ê°€ì¥ ìµœì‹  ë³´ê³ ì„œë¥¼ ê°€ì ¸ì˜¤ê¸°"""
        if self.api_call_count >= self.daily_api_limit:
            return ""

        url = f"{self.base_url}/list.json"
        params = {
            'crtfc_key': self.api_key,
            'corp_code': corp_code,
            'bgn_de': '20230101',  # âœ… 2023ë…„ ì´í›„ ë³´ê³ ì„œë§Œ ì¡°íšŒ
            'end_de': datetime.now().strftime('%Y%m%d'),
            'pblntf_ty': 'A',
            'last_reprt_at': 'Y'
        }

        try:
            response = requests.get(url, params=params)
            if response.status_code != 200:
                return ""

            data = response.json()

            # âœ… íŠ¹ì • ê¸°ì—…(ì‚¼ì„±ì „ì, SKí•˜ì´ë‹‰ìŠ¤)ì˜ ì‘ë‹µ JSON ì €ì¥í•˜ì—¬ í™•ì¸
            if corp_code in ["00126380", "005930"]:  # ì‚¼ì„±ì „ì, SKí•˜ì´ë‹‰ìŠ¤ ë“±
                file_path = os.path.join("debug", f"{corp_code}.json")
                with open(file_path, "w", encoding="utf-8") as f:
                    json.dump(data, f, indent=2, ensure_ascii=False)
                logger.info(f"ğŸ“‚ {corp_code} JSON ë°ì´í„° ì €ì¥ ì™„ë£Œ: {file_path}")

            if data.get("status") == "013":
                self.no_report_count += 1
                return ""

            # âœ… A001(ì‚¬ì—…ë³´ê³ ì„œ), A002(ë°˜ê¸°ë³´ê³ ì„œ), A003(ë¶„ê¸°ë³´ê³ ì„œ) ì¤‘ ìµœì‹  ë³´ê³ ì„œ ì„ íƒ
            preferred_order = ["A001", "A002", "A003"]
            latest_report = None

            for report_type in preferred_order:
                report = next((r for r in data.get('list', []) if r.get('pblntf_detail_ty') == report_type), None)
                if report:
                    latest_report = report
                    break

            if not latest_report:
                return ""

            rcept_no = latest_report['rcept_no']

            # XML ë¬¸ì„œ ë‹¤ìš´ë¡œë“œ ìš”ì²­
            document_url = f"{self.base_url}/document.xml"
            doc_response = requests.get(document_url, params={'crtfc_key': self.api_key, 'rcept_no': rcept_no})

            if doc_response.status_code != 200:
                return ""

            self.api_call_count += 1

            with zipfile.ZipFile(BytesIO(doc_response.content)) as z:
                xml_filename = z.namelist()[0]
                xml_content = z.read(xml_filename).decode('utf-8')

            return xml_content

        except Exception:
            return ""


    def run(self, start_idx=2000, end_idx=3000):
        """ETL ì‹¤í–‰ (ê¸°ì—…ë³„ ê°œë³„ ì¶œë ¥ ì œê±° ë° ìš”ì•½ í†µê³„ë§Œ ì¶œë ¥)"""
        if not self.test_elasticsearch_connection():
            return
        
        self.no_report_count = 0  # âœ… ì‚¬ì—… ë³´ê³ ì„œ ì—†ëŠ” ê¸°ì—… ê°œìˆ˜ ì¹´ìš´íŠ¸ ì¶”ê°€
        self.successful_uploads = 0
        self.failed_uploads = 0

        corps = self.get_corp_list(start_idx, end_idx)
        self.total_companies = len(corps)

        for corp in corps:
            text = self.get_business_report(corp['corp_code'])

            if not text.strip():
                continue  # âœ… ê°œë³„ ê¸°ì—… ì¶œë ¥ ì œê±°

            summary = self.summarizer(text, max_length=500, min_length=100, do_sample=False)[0]['summary_text']
            corp['business_overview'] = text
            corp['summary'] = summary

            response = requests.post(f"{self.es_url}/{self.index_name}/_doc", json=corp, headers={"Content-Type": "application/json"})
            if response.status_code in [200, 201]:
                self.successful_uploads += 1
            else:
                self.failed_uploads += 1

        # âœ… ìµœì¢… ìš”ì•½ ë¡œê·¸ë§Œ ì¶œë ¥
        logger.info("âœ… ETL í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ")
        logger.info(f"ğŸ“Š ì´ ì¡°íšŒëœ ê¸°ì—… ìˆ˜: {self.total_companies}")
        logger.info(f"âœ… ì—…ë¡œë“œ ì„±ê³µ: {self.successful_uploads}ê°œ")
        logger.info(f"âš ï¸ ì—…ë¡œë“œ ì‹¤íŒ¨: {self.failed_uploads}ê°œ")
        logger.info(f"ğŸš« ì‚¬ì—… ë³´ê³ ì„œ ì—†ìŒ: {self.no_report_count}ê°œ")


    def download_corp_codes(self):
        """Download company unique codes and convert to UTF-8"""
        url = f"{self.base_url}/corpCode.xml"
        params = {"crtfc_key": self.api_key}

        try:
            response = requests.get(url, params=params)
            response.raise_for_status()

            with zipfile.ZipFile(BytesIO(response.content)) as zf:
                xml_data = zf.read('CORPCODE.xml').decode("euc-kr")  # âœ… EUC-KR â†’ UTF-8 ë³€í™˜

            # âœ… UTF-8ë¡œ ë³€í™˜ëœ XMLì„ ì €ì¥
            with open("output/corpCode_utf8.xml", "w", encoding="utf-8") as f:
                f.write(xml_data)

            root = ET.fromstring(xml_data)
            for company in root.findall('.//list'):
                corp_code = company.findtext('corp_code')
                stock_code = company.findtext('stock_code')
                if stock_code and stock_code.strip():
                    self.corp_codes[stock_code] = corp_code  # âœ… ê¸°ì—… ì½”ë“œ ì €ì¥

            print("Corporate code list downloaded and converted successfully")

        except Exception as e:
            print(f"Error downloading corporate codes: {e}")
            raise

    import xml.etree.ElementTree as ET

    def get_samsung_corp_code(self):
        """ì‚¼ì„±ì „ìì˜ corp_code í™•ì¸"""
        stock_code = "005930"  # ì‚¼ì„±ì „ìì˜ ì¢…ëª©ì½”ë“œ
        corp_code = self.corp_codes.get(stock_code)

        if corp_code:
            print(f"âœ… ì‚¼ì„±ì „ìì˜ corp_code: {corp_code}")
        else:
            print("âŒ ì‚¼ì„±ì „ìì˜ corp_codeë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ!")


    

if __name__ == "__main__":
    pipeline = DartETLPipeline(batch_size=10, daily_api_limit=1000)
    pipeline.run(start_idx=1000, end_idx=1500)  # âœ… 20ê°œ ê¸°ì—…ë§Œ ì²˜ë¦¬
