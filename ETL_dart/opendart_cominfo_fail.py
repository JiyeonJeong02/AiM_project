"""
ì½”ë“œ ë²ˆí˜¸ ê¸°ì¤€ ìë™ ì¡°íšŒ ì½”ë“œ
- ì½”ë“œ ë²ˆí˜¸ ê¸°ì¤€ìœ¼ë¡œ ìë™ ë¶„ê¸°/ë°˜ê¸°/ì‚¬ì—…ë³´ê³ ì„œ ì¡°íšŒ.
- ê·¸ ì™¸ ë³´ê³ ì„œëŠ” ëª¨ë‘ ì œì™¸í•¨ (filtering)

- ì†Œê¸°ì—… ë¶€í„° ì¡°íšŒ ë¼ì„œ, ë¶„ê¸°/ë°˜ê¸°/ì‚¬ì—…ë³´ê³ ì„œ ëª¨ë‘ ì¡°íšŒê°€ ì•ˆë˜ëŠ” ê¸°ì—…ì´ ë§ìŒ.
- ë”°ë¼ì„œ ê¸°ì—… ì •ë³´ í™•ì¸ ë¶ˆê°€.
- **ëŒ€ê¸°ì—… ìœ„ì£¼ íŠ¹ì • ì½”ë“œë§Œ ë¶ˆëŸ¬ì™€ì„œ ì •ë³´ ì¡°íšŒí•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ë³€ê²½.**
"""
import requests
import zipfile
import os
import json
import time
from io import BytesIO
from bs4 import BeautifulSoup
from dotenv import load_dotenv
import re
import xml.etree.ElementTree as ET

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# Open DART API í‚¤ ê°€ì ¸ì˜¤ê¸°
API_KEY = os.getenv('DART_API_KEY')

# ì €ì¥í•  í´ë” ìƒì„±
save_dir = "downloads"
os.makedirs(save_dir, exist_ok=True)

# ğŸ”¹ `reprt_code` ìš°ì„ ìˆœìœ„ (1ë¶„ê¸° â†’ ë°˜ê¸° â†’ 3ë¶„ê¸° â†’ ì‚¬ì—…)
REPORT_CODES = ["11013", "11012", "11014", "11011"]

# ğŸ”¹ ëª¨ë“  ê¸°ì—…ì˜ `corp_code` ê°€ì ¸ì˜¤ê¸°
def get_all_corp_codes():
    url = f"https://opendart.fss.or.kr/api/corpCode.xml?crtfc_key={API_KEY}"
    response = requests.get(url)

    if response.status_code == 200:
        with zipfile.ZipFile(BytesIO(response.content)) as zfile:
            zfile.extractall(save_dir)
        print("âœ… ê¸°ì—… ì½”ë“œ ZIP ë‹¤ìš´ë¡œë“œ ë° ì¶”ì¶œ ì™„ë£Œ.")

        xml_path = os.path.join(save_dir, "corpCode.xml")
        tree = ET.parse(xml_path)
        root = tree.getroot()

        corp_codes = {}
        for corp in root.findall("list"):
            corp_name = corp.find("corp_name").text.strip()
            corp_code = corp.find("corp_code").text.strip()
            corp_codes[corp_name] = corp_code

        return corp_codes
    else:
        print("âŒ ê¸°ì—… ì½”ë“œ XML ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
        return {}

# ğŸ”¹ íŠ¹ì • ê¸°ì—…ì˜ ìµœì‹  ë³´ê³ ì„œ ì ‘ìˆ˜ë²ˆí˜¸(rcept_no) ê°€ì ¸ì˜¤ê¸° (ê°ì‚¬ë³´ê³ ì„œ í•„í„°ë§)
def get_latest_rcept_no(corp_code):
    for reprt_code in REPORT_CODES:  
        url = "https://opendart.fss.or.kr/api/list.json"
        params = {
            'crtfc_key': API_KEY,
            'corp_code': corp_code,
            'bgn_de': '20240101',
            'end_de': '20241231',
            'reprt_code': reprt_code,
            'page_no': 1,
            'page_count': 100
        }
        
        response = requests.get(url, params=params)
        if response.status_code == 200:
            data = response.json()
            if 'list' in data and len(data['list']) > 0:
                for report in data['list']:
                    if "ê°ì‚¬ë³´ê³ ì„œ" not in report['report_nm']:  # ğŸ”´ ê°ì‚¬ë³´ê³ ì„œ ì œì™¸
                        print(f"ğŸ“Œ {corp_code}: {reprt_code} ë³´ê³ ì„œ ì„ íƒë¨ ({report['report_nm']})")
                        return report['rcept_no']
    
    return None

# ğŸ”¹ íŠ¹ì • ê¸°ì—…ì˜ "ì‚¬ì—… ê°œìš”" ì¶”ì¶œ
def extract_business_overview(corp_name, corp_code):
    rcept_no = get_latest_rcept_no(corp_code)
    if not rcept_no:
        print(f"âš ï¸ {corp_name}({corp_code})ì˜ 1ë¶„ê¸°/ë°˜ê¸°/3ë¶„ê¸°/ì‚¬ì—…ë³´ê³ ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None

    # API ìš”ì²­ URL
    url = "https://opendart.fss.or.kr/api/document.xml"
    params = {'crtfc_key': API_KEY, 'rcept_no': rcept_no}

    # API ìš”ì²­ ë° ZIP íŒŒì¼ ë‹¤ìš´ë¡œë“œ
    response = requests.get(url, params=params)
    if response.status_code == 200:
        with zipfile.ZipFile(BytesIO(response.content)) as z:
            file_list = z.namelist()
            extracted_file = file_list[0]
            xml_path = os.path.join(save_dir, extracted_file)

            with open(xml_path, "wb") as f:
                f.write(z.read(extracted_file))

        print(f"âœ… {corp_name}({corp_code}) ë³´ê³ ì„œ ì €ì¥ ì™„ë£Œ: {xml_path}")
    else:
        return None

    # XML íŒŒì¼ ë¡œë“œ
    with open(xml_path, "r", encoding="utf-8", errors="ignore") as f:
        xml_content = f.read()

    soup = BeautifulSoup(xml_content, features="xml")

    # íŠ¹ì • ì„¹ì…˜ ì¶”ì¶œ í•¨ìˆ˜
    def extract_section(section_title):
        section = soup.find("TITLE", string=lambda text: text and re.search(rf"\d*\.*\s*{section_title}", text))
        if not section:
            return "í•´ë‹¹ ì„¹ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        content = []
        for sibling in section.find_all_next():
            if sibling.name == "TITLE":
                break
            if sibling.name in ["P", "TABLE", "SPAN", "DIV"]:
                text = sibling.get_text(strip=True)
                if text and text not in content:
                    content.append(text)

        return "\n".join(content) if content else "í•´ë‹¹ ì„¹ì…˜ì˜ ë³¸ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    business_overview = extract_section("ì‚¬ì—…ì˜ ê°œìš”")
    return business_overview

# ğŸ”¹ ë³´ê³ ì„œê°€ ìˆëŠ” ê¸°ì—…ë§Œ ì €ì¥
corp_codes = get_all_corp_codes()  # ëª¨ë“  ê¸°ì—…ì˜ `corp_code` ê°€ì ¸ì˜¤ê¸°

valid_data = []
for corp_name, corp_code in list(corp_codes.items())[:50]:  # ì²˜ìŒ 50ê°œ ê¸°ì—…ë§Œ í…ŒìŠ¤íŠ¸
    print(f"\nğŸ“Œ {corp_name}({corp_code}) - ìµœì‹  ë³´ê³ ì„œ ì¡°íšŒ ì¤‘...")
    business_overview = extract_business_overview(corp_name, corp_code)

    if business_overview:
        valid_data.append({"ê¸°ì—…ëª…": corp_name, "ì‚¬ì—… ê°œìš”": business_overview})
    else:
        print(f"âš ï¸ {corp_name}ì˜ ë³´ê³ ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ.")

    time.sleep(1)  # API ìš”ì²­ ì œí•œ ë°©ì§€ë¥¼ ìœ„í•´ 1ì´ˆ ëŒ€ê¸°

# 5. JSON íŒŒì¼ ì €ì¥ (ì‚¬ì—… ê°œìš”ê°€ ìˆëŠ” ê¸°ì—…ë§Œ)
with open("ê¸°ì—…_ì‚¬ì—…ê°œìš”.json", "w", encoding="utf-8") as f:
    json.dump(valid_data, f, ensure_ascii=False, indent=4)

print(f"ğŸ“„ JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ: ê¸°ì—…_ì‚¬ì—…ê°œìš”.json")
