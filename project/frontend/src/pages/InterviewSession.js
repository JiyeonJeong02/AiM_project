import React, { useState, useEffect, useRef } from "react";
import { useLocation } from "react-router-dom";
import SpeechRecognitionComponent from "../components/SpeechRecognition";
import { getInterviewResponse } from "../api/gptService";
import "./InterviewSession.css";

const INTERVIEW_TIME = 60; // ë‹µë³€ ì‹œê°„ (ì´ˆ)

const InterviewSession = () => {
  const location = useLocation();
  const { title, job } = location.state || { title: "AI ë©´ì ‘", job: "ì§ë¬´ ë¯¸ì •" };

  const [conversation, setConversation] = useState([
    { role: "bot", text: "ìê¸°ì†Œê°œë¥¼ í•´ì£¼ì„¸ìš”." },
  ]);
  const [userAnswer, setUserAnswer] = useState("");
  const [isRecording, setIsRecording] = useState(false);
  const [isLoading, setIsLoading] = useState(false);
  const [timeLeft, setTimeLeft] = useState(INTERVIEW_TIME);
  const chatBoxRef = useRef(null);
  const videoRef = useRef(null);
  const timerRef = useRef(null);

  const { startListening, stopListening, resetTranscript } = SpeechRecognitionComponent({
    onResult: (text) => setUserAnswer(text),
  });

  // ì±„íŒ…ì°½ ìë™ ìŠ¤í¬ë¡¤
  useEffect(() => {
    if (chatBoxRef.current) {
      chatBoxRef.current.scrollTop = chatBoxRef.current.scrollHeight;
    }
  }, [conversation]);

  // ì›¹ìº  ì„¤ì • (ì¹´ë©”ë¼ ê¸°ëŠ¥ ìœ ì§€)
  useEffect(() => {
    navigator.mediaDevices
      .getUserMedia({ video: true, audio: true })
      .then((stream) => {
        if (videoRef.current) {
          videoRef.current.srcObject = stream;
        }
      })
      .catch((err) => console.error("âŒ ì›¹ìº  ì ‘ê·¼ ì˜¤ë¥˜:", err));
  }, []);

  // ë´‡ ì§ˆë¬¸ì´ ë‚˜íƒ€ë‚˜ë©´ ìë™ìœ¼ë¡œ ìŒì„± ì¸ì‹ ì‹œì‘
  useEffect(() => {
    if (!isLoading && conversation[conversation.length - 1].role === "bot") {
      resetTranscript();
      startListening();
      setIsRecording(true);
    }
  }, [conversation, isLoading, resetTranscript, startListening]);

  const handleSubmitResponse = async () => {
    if (!userAnswer.trim() || isLoading) return; // ì¤‘ë³µ ìš”ì²­ ë°©ì§€

    stopListening(); // ìŒì„± ì¸ì‹ ì¤‘ë‹¨
    setIsRecording(false);
    setIsLoading(true);
    clearInterval(timerRef.current);

    const currentAnswer = userAnswer.trim();
    setUserAnswer("");
    resetTranscript();

    // ì‚¬ìš©ìì˜ ë‹µë³€ ì¶”ê°€
    setConversation((prev) => [...prev, { role: "user", text: currentAnswer }]);

    // ì„ íƒëœ ì†Œë¶„ë¥˜(job)ë¥¼ ë‘ ë²ˆì§¸ ì¸ìë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.
    const botResponse = await getInterviewResponse(currentAnswer, job);
    setConversation((prev) => [...prev, { role: "bot", text: botResponse }]);

    setIsLoading(false);

    // GPT ì‘ë‹µ í›„ 3ì´ˆ ëŒ€ê¸° í›„ ë‹¤ìŒ ì§ˆë¬¸ì„ ìœ„í•œ ìŒì„± ì¸ì‹ ì‹œì‘
    setTimeout(() => {
      console.log("ğŸ•’ 3ì´ˆ ëŒ€ê¸° í›„ ë‹¤ìŒ ì§ˆë¬¸ ì§„í–‰...");
      resetTranscript();
      startListening();
      setIsRecording(true);
    }, 3000);
  };

  return (
    <div className="interview-session-container">
      <div className="interview-header">
        <h1>{title}</h1>
        <h2>ì§€ì› ì§ë¬´: {job}</h2>
      </div>

      <div className="video-container">
        <video ref={videoRef} autoPlay playsInline />
      </div>

      <div className="chat-box" ref={chatBoxRef}>
        {conversation.map((msg, index) => (
          <p key={index} className={msg.role === "user" ? "user-msg" : "bot-msg"}>
            {msg.text}
          </p>
        ))}
        {isLoading && <p className="loading-msg">ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘...</p>}
      </div>

      {/* ë‹µë³€ ì™„ë£Œ ë²„íŠ¼ (ìŒì„± ì¸ì‹ ì¤‘ì´ë©°, ì‚¬ìš©ìì˜ ë‹µë³€ì´ ìˆì„ ë•Œë§Œ í‘œì‹œ) */}
      {isRecording && userAnswer && (
        <div className="user-input-preview">
          <p>ğŸ—£ ë©´ì ‘ì ë‹µë³€: {userAnswer}</p>
          <button className="submit-button" onClick={handleSubmitResponse}>
            ë‹µë³€ ì™„ë£Œ
          </button>
        </div>
      )}
    </div>
  );
};

export default InterviewSession;
