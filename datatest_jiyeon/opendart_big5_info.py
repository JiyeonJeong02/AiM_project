import requests
import zipfile
import os
import json
import csv
import time
from io import BytesIO
from bs4 import BeautifulSoup
from dotenv import load_dotenv
import re
import xml.etree.ElementTree as ET

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# Open DART API í‚¤ ê°€ì ¸ì˜¤ê¸°
API_KEY = os.getenv("DART_API_KEY")

# ì €ì¥í•  í´ë” ìƒì„±
save_dir = "downloads"
os.makedirs(save_dir, exist_ok=True)

# ğŸ”¹ ëŒ€ê¸°ì—… 5ê°œ ì„ ì • (KOSPI ëŒ€í˜•ì£¼)
corp_codes = {
    "ì‚¼ì„±ì „ì": "00126380",
    "SKí•˜ì´ë‹‰ìŠ¤": "00164779",
    "í˜„ëŒ€ìë™ì°¨": "00164742",
    "ë„¤ì´ë²„": "00184036",
    "ì¹´ì¹´ì˜¤": "00110098",
}

# ğŸ”¹ `reprt_code` ìš°ì„ ìˆœìœ„ (1ë¶„ê¸° â†’ ë°˜ê¸° â†’ 3ë¶„ê¸° â†’ ì‚¬ì—…)
REPORT_CODES = ["11013", "11012", "11014", "11011"]

# ğŸ”¹ API ìš”ì²­ í•¨ìˆ˜ (ìë™ ì¬ì‹œë„ ì¶”ê°€)
def request_with_retry(url, params, max_retries=3, timeout=10):
    session = requests.Session()  # ğŸ”´ ì„¸ì…˜ ìœ ì§€
    for attempt in range(max_retries):
        try:
            response = session.get(url, params=params, timeout=timeout)
            response.raise_for_status()
            return response
        except requests.exceptions.RequestException:
            print(f"âš ï¸ ìš”ì²­ ì‹¤íŒ¨ ({attempt+1}/{max_retries}) - ì¬ì‹œë„ ì¤‘...")
            time.sleep(5)  # 5ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„

    return None  # ìµœëŒ€ ì¬ì‹œë„ í›„ ì‹¤íŒ¨í•˜ë©´ None ë°˜í™˜

# ğŸ”¹ ê¸°ì—… ê°œìš” ì •ë³´ ê°€ì ¸ì˜¤ê¸°
def get_company_info(corp_code):
    url = "https://opendart.fss.or.kr/api/company.json"
    params = {"crtfc_key": API_KEY, "corp_code": corp_code}

    response = request_with_retry(url, params)
    if response:
        data = response.json()
        if data["status"] == "000":
            return {
                "ê¸°ì—…ëª…": data.get("corp_name", "ì •ë³´ ì—†ìŒ"),
                "ì˜ë¬¸ëª…": data.get("corp_name_eng", "ì •ë³´ ì—†ìŒ"),
                "ì„¤ë¦½ì¼": data.get("est_dt", "ì •ë³´ ì—†ìŒ"),
                "ëŒ€í‘œìëª…": data.get("ceo_nm", "ì •ë³´ ì—†ìŒ"),
                "ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸": data.get("bizr_no", "ì •ë³´ ì—†ìŒ"),
                "ë²•ì¸ë“±ë¡ë²ˆí˜¸": data.get("jurir_no", "ì •ë³´ ì—†ìŒ"),
                "ì—…ì¢…": data.get("induty_code", "ì •ë³´ ì—†ìŒ"),
                "ì£¼ê¶Œìƒì¥ ì—¬ë¶€": data.get("stock_name", "ì •ë³´ ì—†ìŒ"),
                "ìƒì¥ì¼": data.get("list_dt", "ì •ë³´ ì—†ìŒ"),
                "í™ˆí˜ì´ì§€": data.get("hm_url", "ì •ë³´ ì—†ìŒ"),
            }
    return {}  # ğŸ”´ ê¸°ë³¸ê°’ ë°˜í™˜ (None ë°©ì§€)

# ğŸ”¹ íŠ¹ì • ê¸°ì—…ì˜ ìµœì‹  ë³´ê³ ì„œ ì ‘ìˆ˜ë²ˆí˜¸(rcept_no) ê°€ì ¸ì˜¤ê¸°
def get_latest_rcept_no(corp_code):
    for reprt_code in REPORT_CODES:
        url = "https://opendart.fss.or.kr/api/list.json"
        params = {
            "crtfc_key": API_KEY,
            "corp_code": corp_code,
            "bgn_de": "20240101",
            "end_de": "20241231",
            "reprt_code": reprt_code,
            "page_no": 1,
            "page_count": 10,
        }

        response = request_with_retry(url, params)
        if response:
            data = response.json()
            if "list" in data and len(data["list"]) > 0:
                for report in data["list"]:
                    if "ê°ì‚¬ë³´ê³ ì„œ" not in report["report_nm"]:
                        return report["rcept_no"]

    return None  # ğŸ”´ ë³´ê³ ì„œ ì—†ìŒ

# ğŸ”¹ íŠ¹ì • ê¸°ì—…ì˜ "ì‚¬ì—… ê°œìš”" ì¶”ì¶œ
def extract_business_overview(corp_name, corp_code):
    rcept_no = get_latest_rcept_no(corp_code)
    if not rcept_no:
        return None

    url = "https://opendart.fss.or.kr/api/document.xml"
    params = {"crtfc_key": API_KEY, "rcept_no": rcept_no}

    response = request_with_retry(url, params)
    if response:
        with zipfile.ZipFile(BytesIO(response.content)) as z:
            file_list = z.namelist()
            extracted_file = file_list[0]
            xml_path = os.path.join(save_dir, extracted_file)

            with open(xml_path, "wb") as f:
                f.write(z.read(extracted_file))

    else:
        return None

    # XML íŒŒì¼ ë¡œë“œ
    with open(xml_path, "r", encoding="utf-8", errors="ignore") as f:
        xml_content = f.read()

    soup = BeautifulSoup(xml_content, features="xml")

    def extract_section(section_title):
        section = soup.find("TITLE", string=lambda text: text and re.search(rf"\d*\.*\s*{section_title}", text))
        if not section:
            return None

        content = []
        for sibling in section.find_all_next():
            if sibling.name == "TITLE":
                break
            if sibling.name in ["P", "TABLE", "SPAN", "DIV"]:
                text = sibling.get_text(strip=True)
                if text and text not in content:
                    content.append(text)

        return "\n".join(content) if content else None

    return extract_section("ì‚¬ì—…ì˜ ê°œìš”")

# ğŸ”¹ ëŒ€ê¸°ì—… 5ê°œ ëŒ€ìƒ ì‹¤í–‰
all_data = []

for corp_name, corp_code in corp_codes.items():
    company_info = get_company_info(corp_code)
    business_overview = extract_business_overview(corp_name, corp_code)

    result = {
        **company_info,
        "ì‚¬ì—… ê°œìš”": business_overview if business_overview else "ì‚¬ì—… ê°œìš” ì—†ìŒ"
    }
    all_data.append(result)

    time.sleep(1)  # API ìš”ì²­ ì œí•œ ë°©ì§€ë¥¼ ìœ„í•´ 1ì´ˆ ëŒ€ê¸°

# ğŸ”¹ CSV íŒŒì¼ë¡œ ì €ì¥
csv_filename = "ëŒ€ê¸°ì—…_íšŒì‚¬_ì‚¬ì—…ê°œìš”.csv"
with open(csv_filename, mode="w", encoding="utf-8-sig", newline="") as file:
    writer = csv.DictWriter(file, fieldnames=all_data[0].keys())
    writer.writeheader()
    writer.writerows(all_data)

print(f"ğŸ“„ CSV íŒŒì¼ ì €ì¥ ì™„ë£Œ: {csv_filename}")
