import React, { useState, useEffect, useRef } from "react";
import { useLocation } from "react-router-dom";
import SpeechRecognitionComponent from "../components/SpeechRecognition";
import { getInterviewResponse } from "../api/gptService";
import "./InterviewSession.css";

const INTERVIEW_TIME = 60;

const InterviewSession = () => {
  // location.state + localStorage ë³‘í•©
  const locationState = useLocation().state || {};
  const storageState = JSON.parse(localStorage.getItem("interviewData") || "{}");
  const state = { ...storageState, ...locationState };

  const title = state.title || "AI ë©´ì ‘";
  const company = state.company || "";
  const job = state.job || "ì§ë¬´ ë¯¸ì •";

  const [conversation, setConversation] = useState([
    { role: "bot", text: "ìê¸°ì†Œê°œë¥¼ í•´ì£¼ì„¸ìš”." },
  ]);
  const [userAnswer, setUserAnswer] = useState("");
  const [isRecording, setIsRecording] = useState(false);
  const [isLoading, setIsLoading] = useState(false);
  const chatBoxRef = useRef(null);
  const videoRef = useRef(null);
  const timerRef = useRef(null);

  const { startListening, stopListening, resetTranscript } = SpeechRecognitionComponent({
    onResult: (text) => setUserAnswer(text),
  });

  // ìŠ¤í¬ë¡¤ ìë™
  useEffect(() => {
    if (chatBoxRef.current) {
      chatBoxRef.current.scrollTop = chatBoxRef.current.scrollHeight;
    }
  }, [conversation]);

  // ì›¹ìº 
  useEffect(() => {
    navigator.mediaDevices.getUserMedia({ video: true, audio: true })
      .then((stream) => {
        if (videoRef.current) {
          videoRef.current.srcObject = stream;
        }
      })
      .catch((err) => console.error("âŒ ì›¹ìº  ì˜¤ë¥˜:", err));
  }, []);

  // ë´‡ ì§ˆë¬¸ -> ìŒì„±ì¸ì‹ ìë™ ì‹œì‘
  useEffect(() => {
    if (!isLoading && conversation[conversation.length - 1].role === "bot") {
      resetTranscript();
      startListening();
      setIsRecording(true);
    }
  }, [conversation, isLoading, resetTranscript, startListening]);

  const handleSubmitResponse = async () => {
    if (!userAnswer.trim() || isLoading) return;
    stopListening();
    setIsRecording(false);
    setIsLoading(true);

    const currentAnswer = userAnswer.trim();
    setUserAnswer("");
    resetTranscript();

    setConversation((prev) => [...prev, { role: "user", text: currentAnswer }]);

    // ë°±ì—”ë“œ ìš”ì²­
    const botResponse = await getInterviewResponse(currentAnswer, company, job);
    setConversation((prev) => [...prev, { role: "bot", text: botResponse }]);

    setIsLoading(false);

    // 3ì´ˆ í›„ ë‹¤ìŒ ì§ˆë¬¸
    setTimeout(() => {
      resetTranscript();
      startListening();
      setIsRecording(true);
    }, 3000);
  };

  return (
    <div className="interview-session-container">
      {/* í—¤ë” */}
      <div className="interview-header">
        <h1>{title}</h1>
        <div className="header-subinfo">
          <p>ì§€ì› ì§ë¬´: {job}</p>
          {company && <p>ê¸°ì—…ëª…: {company}</p>}
        </div>
      </div>

      {/* ë©”ì¸ ì»¨í…ì¸  (ê°€ë¡œ ë ˆì´ì•„ì›ƒ) */}
      <div className="main-content">
        <div className="video-container">
          <video ref={videoRef} autoPlay playsInline muted />
        </div>
        <div className="chat-box" ref={chatBoxRef}>
          {conversation.map((msg, index) => (
            <p key={index} className={msg.role === "user" ? "user-msg" : "bot-msg"}>
              {msg.text}
            </p>
          ))}
          {isLoading && <p className="loading-msg">ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘...</p>}
        </div>
      </div>

      {/* ì‚¬ìš©ì ì…ë ¥ ë¯¸ë¦¬ë³´ê¸° + ë‹µë³€ ë²„íŠ¼ */}
      {isRecording && userAnswer && (
        <div className="user-input-preview">
          <p>ğŸ—£ ë©´ì ‘ì ë‹µë³€: {userAnswer}</p>
          <button className="submit-button" onClick={handleSubmitResponse}>
            ë‹µë³€ ì™„ë£Œ
          </button>
        </div>
      )} 
    </div>
  );
};

export default InterviewSession;
